{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cycUBKuQkltO"},"outputs":[],"source":["input_n_test = 500\n","\n","import math\n","import torch\n","import torch.distributions as TD\n","from torch.utils.data import Dataset, DataLoader\n","from zmq import device\n","import torch.optim as optim\n","import numpy as np\n","from datetime import datetime\n","import functools\n","from scipy.linalg import toeplitz\n","import xgboost as xgb\n","from sklearn.linear_model import LassoCV\n","from tqdm import tqdm\n","\n","# Move model on GPU if available\n","enable_cuda = True\n","device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n","\n","def get_xzy_randn_nl(n_points, ground_truth='H0', rho=0.3, p1 = 25, p2 = 25, device='cuda:0', a = 0.0, **ignored):\n","    p = p1 + p2\n","    cov_vec = rho ** np.arange(p)\n","    cov_mx = torch.FloatTensor(toeplitz(cov_vec)).to(device)\n","    X_all_generator = TD.MultivariateNormal(torch.zeros(p).to(device), cov_mx)\n","    X_all = X_all_generator.sample((n_points,))\n","    Z = X_all[:, :p1]\n","    X = X_all[:, p1:]\n","\n","    beta_z = torch.FloatTensor([1] * 2 + [0] * (p1 - 2)).reshape((-1, 1)).to(device)\n","\n","    if ground_truth == 'H0':\n","\n","        beta_x = torch.FloatTensor([0] * 2 + [0] * (p2 - 2)).reshape((-1, 1)).to(device)\n","\n","    elif ground_truth == 'H1_sparse':\n","\n","        beta_x = torch.FloatTensor([a/math.sqrt(5)] * 5 + [0] * (p2 - 5)).reshape((-1, 1)).to(device)\n","\n","    elif ground_truth == 'H1_dense':\n","\n","        beta_x = torch.FloatTensor([a/math.sqrt(12)] * 12 + [0] * (p2 - 12)).reshape((-1, 1)).to(device)\n","\n","    else:\n","        raise NotImplementedError(f'{ground_truth} has to be H0, H1_sparse or H1_dense')\n","\n","    epsilon = torch.randn(n_points, 1, device=device)*0.5\n","    Y = torch.matmul(Z, beta_z) + torch.matmul(X, beta_x) ** 2 + epsilon\n","\n","    return X, Y, Z\n","\n","def get_xzy_randn_nl_fix(Z, n_points, ground_truth='H0', rho=0.3, p1 = 25, p2 = 25, device='cuda:0', a = 0.0, **ignored):\n","    p = p1 + p2\n","    cov_vec = rho ** np.arange(p)\n","    cov_mx = torch.FloatTensor(toeplitz(cov_vec)).to(device)\n","\n","    Cov_11 = cov_mx[:p1,:p1]\n","    Cov_12 = cov_mx[:p1,p1:]\n","    Cov_21 = cov_mx[p1:,:p1]\n","    Cov_22 = cov_mx[p1:,p1:]\n","\n","\n","    if ground_truth == 'H0':\n","\n","        beta_x = torch.FloatTensor([0] * 2 + [0] * (p2 - 2)).reshape((-1, 1)).to(device)\n","\n","    elif ground_truth == 'H1_sparse':\n","\n","        beta_x = torch.FloatTensor([a/math.sqrt(5)] * 5 + [0] * (p2 - 5)).reshape((-1, 1)).to(device)\n","\n","    elif ground_truth == 'H1_dense':\n","\n","        beta_x = torch.FloatTensor([a/math.sqrt(12)] * 12 + [0] * (p2 - 12)).reshape((-1, 1)).to(device)\n","\n","    else:\n","        raise NotImplementedError(f'{ground_truth} has to be H0, H1_sparse or H1_dense')\n","\n","    beta_z = torch.FloatTensor([1] * 2 + [0] * (p1 - 2)).reshape((-1, 1)).to(device)\n","\n","    Cov_22_inv = torch.inverse(Cov_22)\n","    Condi_Cov = Cov_11 - torch.matmul(torch.matmul(Cov_12, Cov_22_inv), Cov_21)\n","    Condi_Mean_vec = torch.matmul(torch.matmul(Cov_12, Cov_22_inv), Z.T)\n","    temp_generator = TD.MultivariateNormal(Condi_Mean_vec, Condi_Cov)\n","    X = temp_generator.sample((n_points,))\n","\n","    first_term = torch.matmul(beta_z.T, Z.reshape((-1, 1)))\n","\n","    var_term = Cov_11 -  torch.matmul(torch.matmul(Cov_12, Cov_22_inv), Cov_21)\n","    sec_term = torch.matmul(torch.matmul(beta_x.T, var_term), beta_x)\n","\n","    condi_exp_term = torch.matmul(torch.matmul(Cov_12, Cov_22_inv), Z.reshape((-1, 1)))\n","    third_term_temp = torch.matmul(condi_exp_term, condi_exp_term.T)\n","    third_term = torch.matmul(torch.matmul(beta_x.T, third_term_temp), beta_x)\n","\n","    Y = first_term + sec_term + third_term\n","\n","    return X, Y.reshape(-1)\n","\n","\n","\n","def get_p_value_stat(boot_num, M, n, gen_x_all_torch, gen_y_all_torch, x_torch, y_torch, z_torch, boor_rv_type=\"gaussian\"):\n","\n","    d_y = y_torch.shape[1]\n","    d_x = x_torch.shape[1]\n","\n","    w_mx = torch.linalg.vector_norm(z_torch.repeat(n,1,1) - torch.swapaxes(z_torch.repeat(n,1,1), 0, 1), ord = 1, dim = 2)\n","    sigma_w = torch.median(w_mx).item()\n","\n","    u_mx = torch.linalg.vector_norm(x_torch.repeat(n,1,1) - torch.swapaxes(x_torch.repeat(n,1,1), 0, 1), ord = 1, dim = 2)\n","    sigma_u = torch.median(u_mx).item()\n","\n","    # print(sigma_w)\n","    # print(sigma_u)\n","\n","    # sigma_w, sigma_u = 1.0, 1.0\n","\n","    w_mx = torch.linalg.vector_norm(z_torch.repeat(n, 1, 1) - torch.swapaxes(z_torch.repeat(n, 1, 1), 0, 1), ord=1, dim=2)\n","    w_mx = torch.exp(-w_mx / sigma_w)\n","\n","    u_mx_1 = torch.exp(-torch.linalg.vector_norm(x_torch.repeat(n, 1, 1) - torch.swapaxes(x_torch.repeat(n, 1, 1), 0, 1), ord=1, dim=2) / sigma_u)\n","    u_mx_2 = torch.mean(\n","        torch.exp(-torch.linalg.vector_norm(gen_x_all_torch.repeat(n, 1, 1).reshape(n, n, -1, d_x) - x_torch.repeat(1, n).reshape(n, n, 1, d_x), ord=1, dim=3) / sigma_u), dim=2)\n","    u_mx_3 = u_mx_2.T\n","\n","    gen_x_all_torch_rep = gen_x_all_torch.repeat(n, 1, 1).reshape(n, n, -1, d_x)\n","\n","    u_mx_4 = torch.mean(torch.exp(-torch.linalg.vector_norm(gen_x_all_torch_rep - torch.swapaxes(gen_x_all_torch_rep, 0, 1), ord=1, dim=3) / sigma_u) , dim=2)\n","\n","    u_mx = u_mx_1 - u_mx_2 - u_mx_3 + u_mx_4\n","    v_mx_temp = (gen_y_all_torch - y_torch)\n","    v_mx = torch.matmul(v_mx_temp, v_mx_temp.T)\n","    FF_mx = u_mx * v_mx * w_mx * (1 - torch.eye(n).to(device))\n","\n","    stat = 1 / (n - 1) * torch.sum(FF_mx).item()\n","\n","    boottemp = np.array([])\n","    if boor_rv_type == \"rademacher\":\n","        eboot = torch.sign(torch.randn(n, boot_num)).to(device)\n","    elif boor_rv_type == \"gaussian\":\n","        eboot = torch.randn(n, boot_num).to(device)\n","    for bb in range(boot_num):\n","        random_mx = torch.matmul(eboot[:, bb].reshape(-1, 1), eboot[:, bb].reshape(-1, 1).T)\n","        bootmatrix = FF_mx * random_mx\n","        stat_boot = 1 / (n - 1) * torch.sum(bootmatrix).item()\n","        boottemp = np.append(boottemp, stat_boot)\n","    return stat, boottemp\n","\n","\n","class DatasetSelect(Dataset):\n","    def __init__(self, X, Y, Z):\n","        self.X_real = X\n","        self.Y_real = Y\n","        self.Z_real = Z\n","        self.sample_size = X.shape[0]\n","\n","    def __len__(self):\n","        return self.sample_size\n","\n","    def __getitem__(self, index):\n","        return self.X_real[index], self.Y_real[index], self.Z_real[index]\n","\n","# Create a DataLoader for given (X, Y)\n","\n","class DatasetSelect_GAN(torch.utils.data.Dataset):\n","\n","  def __init__(self, X, Y, Z, batch_size):\n","    self.X_real = X\n","    self.Y_real = Y\n","    self.Z_real = Z\n","    self.batch_size = batch_size\n","    self.sample_size = X.shape[0]\n","\n","  def __len__(self):\n","    return self.sample_size\n","\n","  def __getitem__(self, index):\n","    return self.X_real[index], self.Y_real[index], self.Z_real[index], self.Z_real[(self.batch_size+index) % self.sample_size]\n","\n","# Create a DataLoader for given (X, Y)\n","\n","class DatasetSelect_GAN_ver2(torch.utils.data.Dataset):\n","\n","  def __init__(self, Y, Z, batch_size):\n","    self.Y_real = Y\n","    self.Z_real = Z\n","    self.batch_size = batch_size\n","    self.sample_size = Z.shape[0]\n","\n","  def __len__(self):\n","    return self.sample_size\n","\n","  def __getitem__(self, index):\n","    return self.Y_real[index], self.Z_real[index]\n","\n","##### Auxilliary functions #####\n","\n","\n","\n","def mGAN(n=500, z_dim=2, simulation='type1error', x_dims=2, y_dims=2, a_x=0.05, M=500, k=2, boot_num=1000,\n","     boor_rv_type = \"gaussian\", noise_dimension = 50, noise_type = \"normal\", input_var = 1.0/3.0):\n","\n","    sim_x, sim_y, sim_z = get_xzy_randn_nl(n_points = n, ground_truth = simulation, a = a_x)\n","\n","    x, y, z = sim_x.to(device), sim_y.to(device), sim_z.to(device)\n","\n","    test_size = int(n/k)\n","    stat_all = torch.zeros(k, 1)\n","    boot_temp_all = torch.zeros(k, boot_num)\n","    cur_k = 0\n","\n","    for k_fold in range(k):\n","        k_fold_start = int(n/k * k_fold)\n","        k_fold_end = int(n/k * (k_fold+1))\n","        X_test, Y_test, Z_test = x[k_fold_start:k_fold_end], y[k_fold_start:k_fold_end], z[k_fold_start:k_fold_end]\n","        X_train, Y_train, Z_train = torch.cat((x[0:k_fold_start], x[k_fold_end:])), torch.cat((y[0:k_fold_start], y[k_fold_end:])), torch.cat((z[0:k_fold_start], z[k_fold_end:]))\n","\n","        gen_x_all = torch.zeros(test_size, M, x_dims)\n","        gen_y_all = torch.zeros(test_size, y_dims)\n","        z_all = torch.zeros(test_size, z_dim)\n","        x_all = torch.zeros(test_size, x_dims)\n","        y_all = torch.zeros(test_size, y_dims)\n","\n","        # Generate fake data\n","        for i in range(test_size):\n","            gen_x_all[i,:,:], gen_y_all[i,:] = get_xzy_randn_nl_fix(Z = Z_test[i,:], ground_truth = simulation, n_points = M, a = a_x)\n","\n","        gen_y_all = gen_y_all.reshape(-1,y_dims).to(device)\n","\n","        gen_x_all = gen_x_all.detach().to(device)\n","        gen_y_all = gen_y_all.detach().to(device)\n","        z_all = Z_test.to(device)\n","        x_all = X_test.to(device)\n","        y_all = Y_test.to(device)\n","\n","        standardise = True\n","\n","        if standardise:\n","            gen_x_all = (gen_x_all - torch.mean(gen_x_all, dim=0, keepdim=True)) / torch.std(gen_x_all, dim=0, keepdim=True)\n","            gen_y_all = (gen_y_all - torch.mean(gen_y_all, dim=0, keepdim=True)) / torch.std(gen_y_all, dim=0, keepdim=True)\n","            x_all = (x_all - torch.mean(x_all, dim=0, keepdim=True)) / torch.std(x_all, dim=0, keepdim=True)\n","            y_all = (y_all - torch.mean(y_all, dim=0, keepdim=True)) / torch.std(y_all, dim=0, keepdim=True)\n","            z_all = (z_all - torch.mean(z_all, dim=0, keepdim=True)) / torch.std(z_all, dim=0, keepdim=True)\n","\n","        cur_stat, cur_boot_temp = get_p_value_stat(boot_num, M, test_size, gen_x_all.to(device), gen_y_all.to(device),\n","                                x_all.to(device), y_all.to(device), z_all.to(device), boor_rv_type)\n","        stat_all[cur_k,:] = cur_stat\n","        boot_temp_all[cur_k,:] = torch.from_numpy(cur_boot_temp)\n","        cur_k = cur_k + 1\n","\n","    return np.mean(torch.mean(boot_temp_all, dim = 0).numpy() > torch.mean(stat_all).item() )\n","\n","def run_experiment(params):\n","    test = params[\"test\"]\n","    sample_size = params[\"sample_size\"]\n","    z_dim = params[\"z_dim\"]\n","    dx = params[\"dx\"]\n","    dy = params[\"dy\"]\n","    n_test = params[\"n_test\"]\n","    alpha_x = params[\"alpha_x\"]\n","    m_value = params[\"m_value\"]\n","    k_value = params[\"k_value\"]\n","    j_value = params[\"j_value\"]\n","    alpha = params[\"alpha\"]\n","    alpha1 = params[\"alpha1\"]\n","    set_seeds = params[\"set_seeds\"]\n","    boor_rv_type = params[\"boor_rv_type\"]\n","\n","\n","    np.random.seed(set_seeds)\n","    torch.manual_seed(set_seeds)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(set_seeds)\n","\n","    p_values = np.array([])\n","    test_count = 0\n","    if test == 'H0':\n","        for n in tqdm(range(n_test)):\n","            # start_time = datetime.now()\n","\n","            p_value = mGAN(n=sample_size, z_dim=z_dim, simulation=test, x_dims=dx, y_dims=dy, a_x=alpha_x, M=m_value,\n","                    k=k_value, boot_num=j_value, boor_rv_type = boor_rv_type)\n","\n","            # test_count += 1\n","            # print(\"--- The %d'th iteration take %s seconds ---\" % (test_count, (datetime.now() - start_time)))\n","\n","            p_values = np.append(p_values, p_value)\n","            fp = [pval < alpha  for pval in p_values]\n","            final_result = np.mean(fp)\n","            fp1 = [pval < alpha1 for pval in p_values]\n","            final_result1 = np.mean(fp1)\n","\n","            # print('The stat is {}'.format(p_value))\n","            # print('Type 1 error: {} for z dimension {} with significance level {}'.format(final_result, z_dim, alpha))\n","            # print('Type 1 error: {} for z dimension {} with significance level {}'.format(final_result1, z_dim, alpha1))\n","\n","            final_result_list = np.array([final_result])\n","            final_result1_list = np.array([final_result1])\n","\n","        print('Type 1 error: {} with significance level {}'.format(final_result, alpha))\n","        print('Type 1 error: {} with significance level {}'.format(final_result1, alpha1))\n","\n","    if test == 'H1_dense' or test == 'H1_sparse':\n","        for n in tqdm(range(n_test)):\n","            # start_time = datetime.now()\n","\n","            p_value = mGAN(n=sample_size, z_dim=z_dim, simulation=test, x_dims=dx, y_dims=dy, a_x=alpha_x, M=m_value,\n","                    k=k_value, boot_num=j_value, boor_rv_type = boor_rv_type)\n","\n","            # test_count += 1\n","            # print(\"--- The %d'th iteration take %s seconds ---\" % (test_count, (datetime.now() - start_time)))\n","\n","            p_values = np.append(p_values, p_value)\n","            fp = [pval < alpha  for pval in p_values]\n","            final_result = np.mean(fp)\n","            fp1 = [pval < alpha1 for pval in p_values]\n","            final_result1 = np.mean(fp1)\n","\n","            # print('The stat is {}'.format(p_value))\n","            # print('Power: {} for z dimension {} with significance level {}'.format(final_result, z_dim, alpha))\n","            # print('Power: {} for z dimension {} with significance level {}'.format(final_result1, z_dim, alpha1))\n","\n","            final_result_list = np.array([final_result])\n","            final_result1_list = np.array([final_result1])\n","\n","        print('Power: {} with significance level {}'.format(final_result, alpha))\n","        print('Power: {} with significance level {}'.format(final_result1, alpha1))\n","\n","    return p_values"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFIHamp4gnyy","executionInfo":{"status":"ok","timestamp":1733460269922,"user_tz":360,"elapsed":400363,"user":{"displayName":"Linjun Huang","userId":"03749337197712996902"}},"outputId":"7703505f-b789-404a-fc8e-728a2748c71b"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["---                     ---\n","---                     ---\n","--- The n =  800  case ---\n","--- The H0 case ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["  0%|          | 0/500 [00:00<?, ?it/s]<ipython-input-1-0b36062acf33>:82: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n","  Condi_Mean_vec = torch.matmul(torch.matmul(Cov_12, Cov_22_inv), Z.T)\n","100%|██████████| 500/500 [16:00<00:00,  1.92s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Type 1 error: 0.138 with significance level 0.1\n","Type 1 error: 0.072 with significance level 0.05\n","--- The H1_dense case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [15:47<00:00,  1.90s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 1.0 with significance level 0.1\n","Power: 1.0 with significance level 0.05\n","Adjusted Power: 1.0 with significance level 0.07250000000000002\n","Adjusted Power: 0.998 with significance level 0.03380000000000001\n","--- The H1_sparse case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [15:46<00:00,  1.89s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 1.0 with significance level 0.1\n","Power: 1.0 with significance level 0.05\n","Adjusted Power: 1.0 with significance level 0.07250000000000002\n","Adjusted Power: 1.0 with significance level 0.03380000000000001\n","---                     ---\n","---                     ---\n","--- The n =  600  case ---\n","--- The H0 case ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [12:29<00:00,  1.50s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Type 1 error: 0.12 with significance level 0.1\n","Type 1 error: 0.056 with significance level 0.05\n","--- The H1_dense case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [13:33<00:00,  1.63s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 0.968 with significance level 0.1\n","Power: 0.92 with significance level 0.05\n","Adjusted Power: 0.962 with significance level 0.0879\n","Adjusted Power: 0.912 with significance level 0.04385000000000001\n","--- The H1_sparse case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [12:24<00:00,  1.49s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 0.998 with significance level 0.1\n","Power: 0.994 with significance level 0.05\n","Adjusted Power: 0.998 with significance level 0.0879\n","Adjusted Power: 0.992 with significance level 0.04385000000000001\n","---                     ---\n","---                     ---\n","--- The n =  400  case ---\n","--- The H0 case ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [11:04<00:00,  1.33s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Type 1 error: 0.128 with significance level 0.1\n","Type 1 error: 0.068 with significance level 0.05\n","--- The H1_dense case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [09:35<00:00,  1.15s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 0.82 with significance level 0.1\n","Power: 0.68 with significance level 0.05\n","Adjusted Power: 0.77 with significance level 0.07390000000000001\n","Adjusted Power: 0.574 with significance level 0.031950000000000006\n","--- The H1_sparse case Empirical Power ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [08:53<00:00,  1.07s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Power: 0.944 with significance level 0.1\n","Power: 0.862 with significance level 0.05\n","Adjusted Power: 0.916 with significance level 0.07390000000000001\n","Adjusted Power: 0.8 with significance level 0.031950000000000006\n","---                     ---\n","---                     ---\n","--- The n =  200  case ---\n","--- The H0 case ---\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [05:32<00:00,  1.51it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Type 1 error: 0.13 with significance level 0.1\n","Type 1 error: 0.07 with significance level 0.05\n","--- The H1_dense case Empirical Power ---\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [05:31<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Power: 0.44 with significance level 0.1\n","Power: 0.276 with significance level 0.05\n","Adjusted Power: 0.4 with significance level 0.07980000000000001\n","Adjusted Power: 0.238 with significance level 0.039900000000000005\n","--- The H1_sparse case Empirical Power ---\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [05:38<00:00,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["Power: 0.56 with significance level 0.1\n","Power: 0.408 with significance level 0.05\n","Adjusted Power: 0.514 with significance level 0.07980000000000001\n","Adjusted Power: 0.368 with significance level 0.039900000000000005\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["for input_sample_size in [800, 600, 400, 200]:\n","    print(\"---                     ---\")\n","    print(\"---                     ---\")\n","    print(\"--- The n = \",input_sample_size,\" case ---\")\n","\n","    param = {\n","      \"test\": \"H0\", # ['H0', 'H1_dense', 'H1_sparse']\n","      \"sample_size\":  input_sample_size, # [100, 200, 300, 400]\n","      \"z_dim\": 25, # [5, 50, 250]\n","      \"dx\": 25,\n","      \"dy\": 1,\n","      \"n_test\": input_n_test, # [500] in the paper\n","      \"alpha_x\": 0.50, # only used under alternative ['power_sparse': a = 0.5; 'power_dense': 1/sqrt(2*p2) {1/math.sqrt(2*25)}]\n","      \"m_value\": 100, # [500]\n","      \"k_value\": 2, # [1, 2, 4]\n","      \"j_value\": 1000, # [1000, 2000]\n","      \"alpha\": 0.1,\n","      \"alpha1\": 0.05,\n","      \"set_seeds\": 42,\n","      \"boor_rv_type\":  'rademacher' # ['rademacher', 'gaussian']\n","    }\n","\n","    print(\"--- The H0 case ---\")\n","    p_val_list = run_experiment(param)\n","\n","    import numpy as np\n","    quantile_5, quantile_10 = np.quantile(p_val_list, 0.05), np.quantile(p_val_list, 0.10)\n","\n","    param = {\n","      \"test\": \"H1_dense\", # ['H0', 'H1_dense', 'H1_sparse']\n","      \"sample_size\":  input_sample_size, # [100, 200, 300, 400]\n","      \"z_dim\": 25, # [5, 50, 250]\n","      \"dx\": 25,\n","      \"dy\": 1,\n","      \"n_test\": input_n_test, # [500] in the paper\n","      \"alpha_x\": 0.50, # only used under alternative ['power_sparse': a = 0.5; 'power_dense': 1/sqrt(2*p2) {1/math.sqrt(2*25)}]\n","      \"m_value\": 100, # [500]\n","      \"k_value\": 2, # [1, 2, 4]\n","      \"j_value\": 1000, # [1000, 2000]\n","      \"alpha\": 0.1,\n","      \"alpha1\": 0.05,\n","      \"set_seeds\": 42,\n","      \"boor_rv_type\":  'rademacher' # ['rademacher', 'gaussian']\n","    }\n","\n","    print(\"--- The H1_dense case Empirical Power ---\")\n","    p_val_list_H1_dense = run_experiment(param)\n","\n","    fp = [pval < quantile_10  for pval in p_val_list_H1_dense]\n","    final_result = np.mean(fp)\n","    fp1 = [pval < quantile_5 for pval in p_val_list_H1_dense]\n","    final_result1 = np.mean(fp1)\n","\n","\n","    print('Adjusted Power: {} with significance level {}'.format(final_result, quantile_10))\n","    print('Adjusted Power: {} with significance level {}'.format(final_result1, quantile_5))\n","\n","    param = {\n","      \"test\": \"H1_sparse\", # ['H0', 'H1_dense', 'H1_sparse']\n","      \"sample_size\":  input_sample_size, # [100, 200, 300, 400]\n","      \"z_dim\": 25, # [5, 50, 250]\n","      \"dx\": 25,\n","      \"dy\": 1,\n","      \"n_test\": input_n_test, # [500] in the paper\n","      \"alpha_x\": 0.50, # only used under alternative ['power_sparse': a = 0.5; 'power_dense': 1/sqrt(2*p2) {1/math.sqrt(2*25)}]\n","      \"m_value\": 100, # [500]\n","      \"k_value\": 2, # [1, 2, 4]\n","      \"j_value\": 1000, # [1000, 2000]\n","      \"alpha\": 0.1,\n","      \"alpha1\": 0.05,\n","      \"set_seeds\": 42,\n","      \"boor_rv_type\":  'rademacher' # ['rademacher', 'gaussian']\n","    }\n","\n","    print(\"--- The H1_sparse case Empirical Power ---\")\n","    p_val_list_H1_sparse = run_experiment(param)\n","\n","    fp = [pval < quantile_10  for pval in p_val_list_H1_sparse]\n","    final_result = np.mean(fp)\n","    fp1 = [pval < quantile_5 for pval in p_val_list_H1_sparse]\n","    final_result1 = np.mean(fp1)\n","\n","\n","    print('Adjusted Power: {} with significance level {}'.format(final_result, quantile_10))\n","    print('Adjusted Power: {} with significance level {}'.format(final_result1, quantile_5))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}